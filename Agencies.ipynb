{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import subprocess\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "servers = ['Algeria','Egypt','Ghana',\"Argentina\", \"Bahamas\", \"Bermuda\", \"Bolivia\", \"Brazil\", \"Brazil - 2\",'Kenya','Israel','Morocco','Lebanon',\n",
    "           'South Africa','Albania','Andorra','Armenia']\n",
    "\n",
    "def rotate_vpn(servers):\n",
    "    while True:\n",
    "        try:\n",
    "            random_server = random.choice(servers)\n",
    "            subprocess.run(['expressvpn', 'disconnect'], check=True)\n",
    "            subprocess.run(['expressvpn', 'connect', random_server], check=True)\n",
    "            print(f\"Connected to {random_server}\")\n",
    "            time.sleep(5)  # Give the VPN time to stabilize\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to switch VPN server: {e}\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopping VPN rotation.\")\n",
    "            break\n",
    "        time.sleep(100) \n",
    "\n",
    "# Start the VPN rotation in a separate thread\n",
    "stop_event = threading.Event()\n",
    "vpn_thread = threading.Thread(target=rotate_vpn, args=(servers,))\n",
    "vpn_thread.start()\n",
    "\n",
    "baseurl = \"https://themanifest.com\"\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.6533.103 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPod; CPU iPhone OS 17_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/127.0.6533.107 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (iPad; CPU OS 17_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/127.0.6533.107 Mobile/15E148 Safari/604.1\"\n",
    "    # Add more user agents here\n",
    "]\n",
    "user_agent = random.choice(USER_AGENTS)\n",
    "headers = {\n",
    "    'User-Agent': user_agent\n",
    "}\n",
    "baseurl = \"https://themanifest.com\"\n",
    "agencylinks = []\n",
    "\n",
    "for x in range(1):\n",
    "    url = f\"https://themanifest.com/ke/advertising/agencies?page={x}\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "    # Find all <a> tags with the class \"provider-card__profile-link\"\n",
    "    profile_links = soup.find_all('a', class_='provider-card__profile-link')\n",
    "    \n",
    "    # Extract the href attributes and concatenate with baseurl\n",
    "    urls = [baseurl + link['href'] for link in profile_links]\n",
    "    \n",
    "    # Store the concatenated URLs in agencylinks\n",
    "    agencylinks.extend(urls)\n",
    "\n",
    "\n",
    "    # Code to get all the data from each link\n",
    "    agency_list = []\n",
    "    for link in agencylinks:\n",
    "        r = requests.get(link, headers=headers)\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    \n",
    "        # Initialize variables with default values\n",
    "        agency_name = \"Not available\"\n",
    "        website_link = \"Not available\"\n",
    "        date_started = \"Not available\"\n",
    "        location = \"Not available\"\n",
    "        no_of_employees = \"Not available\"\n",
    "        services = \"Not available\"\n",
    "        min_project_size = \"Not available\"\n",
    "\n",
    "\n",
    "\n",
    "        # Extract data and replace default values if data is found\n",
    "        agency_name = soup.find(\"a\", {\"class\":\"profile-information__company-title profile-information__company-link--tracking\"})\n",
    "        if agency_name:\n",
    "            agency_name=agency_name.text.strip()\n",
    "        \n",
    "        website_link=soup.find('a', class_='profile-information__company-link profile-information__company-link--tracking')\n",
    "        if website_link:\n",
    "            # Extract the text content within the anchor tag\n",
    "            link_text = website_link.text.strip()\n",
    "\n",
    "            # Extract the href attribute value\n",
    "            link_url = website_link.get('href')  # Get the link URL with the 'href' attribute\n",
    "\n",
    "        services = soup.find_all(\"div\", {\"class\":\"client__industry\"})\n",
    "        service = [service.text.strip() for service in services]\n",
    "        # Join the text with commas\n",
    "        services = ', '.join(service)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        agency_size = soup.find('div', class_='profile-information__item-icon employees custom_popover').next_sibling\n",
    "        if agency_size:\n",
    "            no_of_employees=agency_size.text.strip()\n",
    "        \n",
    "\n",
    "        agency_location = soup.find(\"div\", {\"data-content\":\"<i>Company Size</i>\"})\n",
    "        if agency_location :\n",
    "            location=agency_location .text.strip()\n",
    "\n",
    "        project_size= soup.find(\"span\", {\"class\":\"profile-information__property-text\"})\n",
    "        if project_size :\n",
    "            min_project_size=project_size.text.strip()\n",
    "        \n",
    "        description= soup.find(\"div\", {\"class\":\"profile-information__description profile-information__description--bottom\"})\n",
    "        if description :\n",
    "            date_started=description.text.strip()\n",
    "    \n",
    "\n",
    "\n",
    "            # Create dictionary and append to list\n",
    "        agencies = {\n",
    "            \"agency_name\": agency_name,\n",
    "            'link_text':link_text,\n",
    "            'link_url':link_url,\n",
    "            \"website_link\": website_link,\n",
    "            \"location\":location,\n",
    "            \"date_started\": date_started,\n",
    "            \"no_of_employees\": no_of_employees,\n",
    "            \"min_project_size\": min_project_size,\n",
    "            \"services\": services\n",
    "        }\n",
    "        agency_list.append(agencies)\n",
    "        print(\"agency_name:\", agencies['agency_name'])\n",
    "\n",
    "\n",
    "# # Stop the VPN thread if scraping is completed\n",
    "stop_event.set()  # Signal the VPN thread to stop\n",
    "vpn_thread.join()\n",
    "\n",
    "df=pd.DataFrame(agency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_name</th>\n",
       "      <th>link_text</th>\n",
       "      <th>link_url</th>\n",
       "      <th>website_link</th>\n",
       "      <th>location</th>\n",
       "      <th>date_started</th>\n",
       "      <th>no_of_employees</th>\n",
       "      <th>min_project_size</th>\n",
       "      <th>services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SmartSites</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://www.smartsites.com/lp/digital-marketin...</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td></td>\n",
       "      <td>SmartSites is a full-service digital agency lo...</td>\n",
       "      <td>250 - 999\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>eCommerce\\n      20%, Automotive\\n      15%, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SmartSites</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://www.smartsites.com/lp/digital-marketin...</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td></td>\n",
       "      <td>SmartSites is a full-service digital agency lo...</td>\n",
       "      <td>250 - 999\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>eCommerce\\n      20%, Automotive\\n      15%, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHARLESON®</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://charleson.co.ke</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td></td>\n",
       "      <td>Charleson Group is a digital marketing firm ba...</td>\n",
       "      <td>10 - 49\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>eCommerce\\n      20%, Information technology\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHARLESON®</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://charleson.co.ke</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td></td>\n",
       "      <td>Charleson Group is a digital marketing firm ba...</td>\n",
       "      <td>10 - 49\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>eCommerce\\n      20%, Information technology\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHARLESON®</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://charleson.co.ke</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td></td>\n",
       "      <td>Charleson Group is a digital marketing firm ba...</td>\n",
       "      <td>10 - 49\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>eCommerce\\n      20%, Information technology\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agency_name   link_text                                           link_url  \\\n",
       "0  SmartSites  visit site  https://www.smartsites.com/lp/digital-marketin...   \n",
       "1  SmartSites  visit site  https://www.smartsites.com/lp/digital-marketin...   \n",
       "2  CHARLESON®  visit site                            https://charleson.co.ke   \n",
       "3  CHARLESON®  visit site                            https://charleson.co.ke   \n",
       "4  CHARLESON®  visit site                            https://charleson.co.ke   \n",
       "\n",
       "             website_link location  \\\n",
       "0  [\\n    visit site\\n  ]            \n",
       "1  [\\n    visit site\\n  ]            \n",
       "2  [\\n    visit site\\n  ]            \n",
       "3  [\\n    visit site\\n  ]            \n",
       "4  [\\n    visit site\\n  ]            \n",
       "\n",
       "                                        date_started  \\\n",
       "0  SmartSites is a full-service digital agency lo...   \n",
       "1  SmartSites is a full-service digital agency lo...   \n",
       "2  Charleson Group is a digital marketing firm ba...   \n",
       "3  Charleson Group is a digital marketing firm ba...   \n",
       "4  Charleson Group is a digital marketing firm ba...   \n",
       "\n",
       "                            no_of_employees min_project_size  \\\n",
       "0  250 - 999\\n        \\n          employees          $1,000+   \n",
       "1  250 - 999\\n        \\n          employees          $1,000+   \n",
       "2    10 - 49\\n        \\n          employees          $1,000+   \n",
       "3    10 - 49\\n        \\n          employees          $1,000+   \n",
       "4    10 - 49\\n        \\n          employees          $1,000+   \n",
       "\n",
       "                                            services  \n",
       "0  eCommerce\\n      20%, Automotive\\n      15%, D...  \n",
       "1  eCommerce\\n      20%, Automotive\\n      15%, D...  \n",
       "2  eCommerce\\n      20%, Information technology\\n...  \n",
       "3  eCommerce\\n      20%, Information technology\\n...  \n",
       "4  eCommerce\\n      20%, Information technology\\n...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "servers = ['Algeria', 'Egypt', 'Ghana', \"Argentina\", \"Bahamas\", \"Bermuda\", \"Bolivia\", \"Brazil\", \"Brazil - 2\", 'Kenya', 'Israel', 'Morocco', 'Lebanon',\n",
    "           'South Africa', 'Albania', 'Andorra', 'Armenia']\n",
    "\n",
    "def rotate_vpn(servers):\n",
    "    while True:\n",
    "        try:\n",
    "            random_server = random.choice(servers)\n",
    "            subprocess.run(['expressvpn', 'disconnect'], check=True)\n",
    "            subprocess.run(['expressvpn', 'connect', random_server], check=True)\n",
    "            print(f\"Connected to {random_server}\")\n",
    "            time.sleep(5)  # Give the VPN time to stabilize\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to switch VPN server: {e}\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopping VPN rotation.\")\n",
    "            break\n",
    "        time.sleep(500) \n",
    "\n",
    "# Start the VPN rotation in a separate thread\n",
    "stop_event = threading.Event()\n",
    "vpn_thread = threading.Thread(target=rotate_vpn, args=(servers,))\n",
    "vpn_thread.start()\n",
    "\n",
    "baseurl = \"https://themanifest.com\"\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.6533.103 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPod; CPU iPhone OS 17_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/127.0.6533.107 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (iPad; CPU OS 17_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/127.0.6533.107 Mobile/15E148 Safari/604.1\"\n",
    "    # Add more user agents here\n",
    "]\n",
    "user_agent = random.choice(USER_AGENTS)\n",
    "headers = {\n",
    "    'User-Agent': user_agent\n",
    "}\n",
    "agencylinks = []\n",
    "\n",
    "for x in range(6):\n",
    "    url = f\"https://themanifest.com/ke/advertising/agencies?page={x}\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "    # Find all <a> tags with the class \"provider-card__profile-link\"\n",
    "    profile_links = soup.find_all('a', class_='provider-card__profile-link')\n",
    "    \n",
    "    # Extract the href attributes and concatenate with baseurl\n",
    "    urls = [baseurl + link['href'] for link in profile_links]\n",
    "    \n",
    "    # Store the concatenated URLs in agencylinks\n",
    "    agencylinks.extend(urls)\n",
    "\n",
    "\n",
    "# Code to get all the data from each link\n",
    "agency_list = []\n",
    "\n",
    "for link in agencylinks:\n",
    "    r = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    \n",
    "    # Initialize variables with default values\n",
    "    agency_name = \"Not available\"\n",
    "    website_link = \"Not available\"\n",
    "    date_started = \"Not available\"\n",
    "    location = \"Not available\"\n",
    "    no_of_employees = \"Not available\"\n",
    "    services = \"Not available\"\n",
    "    min_project_size = \"Not available\"\n",
    "\n",
    "    # Extract data and replace default values if data is found\n",
    "    agency_name_tag = soup.find(\"a\", {\"class\":\"profile-information__company-title profile-information__company-link--tracking\"})\n",
    "    if agency_name_tag:\n",
    "        agency_name = agency_name_tag.text.strip()\n",
    "\n",
    "    # Check if the agency is already in the list\n",
    "    if any(agency['agency_name'] == agency_name for agency in agency_list):\n",
    "        print(f\"Skipping {agency_name} as it already exists in the list.\")\n",
    "        continue\n",
    "    \n",
    "    website_link_tag = soup.find('a', class_='profile-information__company-link profile-information__company-link--tracking')\n",
    "    if website_link_tag:\n",
    "        link_text = website_link_tag.text.strip()\n",
    "        link_url = website_link_tag.get('href')\n",
    "\n",
    "    services_tags = soup.find_all(\"div\", {\"class\":\"client__industry\"})\n",
    "    service = [service.text.strip() for service in services_tags]\n",
    "    services = ', '.join(service)\n",
    "\n",
    "    agency_size_tag = soup.find('div', class_='profile-information__item-icon employees custom_popover')\n",
    "    if agency_size_tag:\n",
    "        next_sibling = agency_size_tag.next_sibling\n",
    "        if next_sibling:\n",
    "            no_of_employees = next_sibling.text.strip()\n",
    "        else:\n",
    "            no_of_employees = None\n",
    "    else:\n",
    "        no_of_employees = None\n",
    "\n",
    "    agency_location_tag = soup.find(\"span\", {\"class\":\"locality\"})\n",
    "    if agency_location_tag:\n",
    "        location = agency_location_tag.text.strip()\n",
    "\n",
    "    project_size_tag = soup.find(\"span\", {\"class\":\"profile-information__property-text\"})\n",
    "    if project_size_tag:\n",
    "        min_project_size = project_size_tag.text.strip()\n",
    "\n",
    "    description_tag = soup.find(\"div\", {\"class\":\"profile-information__description profile-information__description--bottom\"})\n",
    "    if description_tag:\n",
    "        date_started = description_tag.text.strip()\n",
    "\n",
    "    # Create dictionary and append to list\n",
    "    agencies = {\n",
    "        \"agency_name\": agency_name,\n",
    "        'link_text': link_text,\n",
    "        'link_url': link_url,\n",
    "        \"website_link\": website_link_tag,\n",
    "        \"location\": location,\n",
    "        \"date_started\": date_started,\n",
    "        \"no_of_employees\": no_of_employees,\n",
    "        \"min_project_size\": min_project_size,\n",
    "        \"services\": services\n",
    "    }\n",
    "    agency_list.append(agencies)\n",
    "    print(f\"Added {agency_name} to the list.\")\n",
    "\n",
    "# Stop the VPN thread if scraping is completed\n",
    "stop_event.set()  # Signal the VPN thread to stop\n",
    "vpn_thread.join()\n",
    "\n",
    "df = pd.DataFrame(agency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_name</th>\n",
       "      <th>link_text</th>\n",
       "      <th>link_url</th>\n",
       "      <th>website_link</th>\n",
       "      <th>location</th>\n",
       "      <th>date_started</th>\n",
       "      <th>no_of_employees</th>\n",
       "      <th>min_project_size</th>\n",
       "      <th>services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SmartSites</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://www.smartsites.com/lp/digital-marketin...</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td>Paramus, NJ</td>\n",
       "      <td>SmartSites is a full-service digital agency lo...</td>\n",
       "      <td>250 - 999\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>eCommerce\\n      20%, Automotive\\n      15%, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHARLESON®</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://charleson.co.ke</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>Charleson Group is a digital marketing firm ba...</td>\n",
       "      <td>10 - 49\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>eCommerce\\n      20%, Information technology\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith Aegis Plc - Marketing Agency Kenya</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://www.smithcorp.co.ke</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>Smith Aegis Plc is a marketing firm founded in...</td>\n",
       "      <td>10 - 49\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>Advertising &amp; marketing\\n      10%, Media\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Seasons Communications Limited</td>\n",
       "      <td>visit site</td>\n",
       "      <td>http://allseasonscommunications.co.ke</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>All Seasons Communications Limited is a digita...</td>\n",
       "      <td>2 - 9\\n        \\n          employees</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Advertising &amp; marketing\\n      90%, eCommerce\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H&amp;S Reliance Group Ltd- Web Design, Mobile App...</td>\n",
       "      <td>visit site</td>\n",
       "      <td>https://www.hsreliancegroup.com/</td>\n",
       "      <td>[\\n    visit site\\n  ]</td>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>H&amp;S Reliance Group Ltd- Web Design, Mobile App...</td>\n",
       "      <td>10 - 49\\n        \\n          employees</td>\n",
       "      <td>$1,000+</td>\n",
       "      <td>Advertising &amp; marketing\\n      100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         agency_name   link_text  \\\n",
       "0                                         SmartSites  visit site   \n",
       "1                                         CHARLESON®  visit site   \n",
       "2           Smith Aegis Plc - Marketing Agency Kenya  visit site   \n",
       "3                 All Seasons Communications Limited  visit site   \n",
       "4  H&S Reliance Group Ltd- Web Design, Mobile App...  visit site   \n",
       "\n",
       "                                            link_url            website_link  \\\n",
       "0  https://www.smartsites.com/lp/digital-marketin...  [\\n    visit site\\n  ]   \n",
       "1                            https://charleson.co.ke  [\\n    visit site\\n  ]   \n",
       "2                        https://www.smithcorp.co.ke  [\\n    visit site\\n  ]   \n",
       "3              http://allseasonscommunications.co.ke  [\\n    visit site\\n  ]   \n",
       "4                   https://www.hsreliancegroup.com/  [\\n    visit site\\n  ]   \n",
       "\n",
       "         location                                       date_started  \\\n",
       "0     Paramus, NJ  SmartSites is a full-service digital agency lo...   \n",
       "1  Nairobi, Kenya  Charleson Group is a digital marketing firm ba...   \n",
       "2  Nairobi, Kenya  Smith Aegis Plc is a marketing firm founded in...   \n",
       "3  Nairobi, Kenya  All Seasons Communications Limited is a digita...   \n",
       "4  Nairobi, Kenya  H&S Reliance Group Ltd- Web Design, Mobile App...   \n",
       "\n",
       "                            no_of_employees min_project_size  \\\n",
       "0  250 - 999\\n        \\n          employees          $1,000+   \n",
       "1    10 - 49\\n        \\n          employees          $1,000+   \n",
       "2    10 - 49\\n        \\n          employees          $1,000+   \n",
       "3      2 - 9\\n        \\n          employees      Undisclosed   \n",
       "4    10 - 49\\n        \\n          employees          $1,000+   \n",
       "\n",
       "                                            services  \n",
       "0  eCommerce\\n      20%, Automotive\\n      15%, D...  \n",
       "1  eCommerce\\n      20%, Information technology\\n...  \n",
       "2  Advertising & marketing\\n      10%, Media\\n   ...  \n",
       "3  Advertising & marketing\\n      90%, eCommerce\\...  \n",
       "4                Advertising & marketing\\n      100%  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('agencies.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
